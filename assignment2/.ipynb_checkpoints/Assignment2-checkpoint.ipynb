{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from fa2 import ForceAtlas2 as FA2 # pip install fa2\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "import numpy as np\n",
    "import community # pip install python-louvain\n",
    "import random\n",
    "import io\n",
    "import unicodedata\n",
    "import unidecode # pip install Unidecode\n",
    "from wordcloud import WordCloud # pip install wordcloud\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-80b6319f8b3d>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-80b6319f8b3d>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    _Exercise 4 - TF-IDF of the republican and democratic tweets\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Part 2 - What do republican and democratic members tweet about?\n",
    "\n",
    "**Exercise 4 - TF-IDF of the republican and democratic tweets**\n",
    "\n",
    "We will create two documents, one containing the words extracted from tweets of republican members, and the other for Democratic members. We will then use TF-IDF to compare the content of these two documents and create a word-cloud. The procedure you should use is exactly the same you used in exercise 2 of week 7. The main steps are summarized below:\n",
    "\n",
    "* Create two large documents, one for the democratic and one for the republican party. Tokenize the pages, and combine the tokens into one long list including all the pages of the members of the same party.\n",
    "* Exclude all twitter handles.\n",
    "* Exclude punctuation.\n",
    "* Exclude stop words (if you don't know what stop words are, go back and read NLPP1e again).\n",
    "* Exclude numbers (since they're difficult to interpret in the word cloud).\n",
    "* Set everything to lower case.\n",
    "* Compute the TF-IDF for each document.\n",
    "* Now, create word-cloud for each party. Are these topics less \"boring\" than the wikipedia topics? Why? Comment on the results.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
